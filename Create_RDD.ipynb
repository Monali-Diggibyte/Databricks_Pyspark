{"cells":[{"cell_type":"code","source":["pip install findspark\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"31c05861-5f04-4465-b35c-226f494e7b9f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Python interpreter will be restarted.\nCollecting findspark\n  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\nInstalling collected packages: findspark\nSuccessfully installed findspark-2.0.1\nPython interpreter will be restarted.\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Python interpreter will be restarted.\nCollecting findspark\n  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\nInstalling collected packages: findspark\nSuccessfully installed findspark-2.0.1\nPython interpreter will be restarted.\n"]}}],"execution_count":0},{"cell_type":"code","source":["import findspark\nfindspark.init()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f17f8e85-ff62-4a39-91f0-c84a6d5173ab"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql import SparkSession, types"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7a7d208b-c55f-4df4-87c6-184cb3086aa4"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["spark = SparkSession.builder.appName('MyPractise').getOrCreate()\nspark"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"35663b10-88e5-4083-b572-c0a64945f47f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=4064341366388844#setting/sparkui/0721-161751-3b7zinlq/driver-4375866537224583447\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.2.1</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[8]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=4064341366388844#setting/sparkui/0721-161751-3b7zinlq/driver-4375866537224583447\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.2.1</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[8]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "]}}],"execution_count":0},{"cell_type":"code","source":["sc = spark.sparkContext\nsc"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"23b619f2-e463-4065-a01c-050b76b00475"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"\n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=4064341366388844#setting/sparkui/0721-161751-3b7zinlq/driver-4375866537224583447\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.2.1</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[8]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        ","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["\n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=4064341366388844#setting/sparkui/0721-161751-3b7zinlq/driver-4375866537224583447\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.2.1</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[8]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        "]}}],"execution_count":0},{"cell_type":"code","source":["name_list = ['Azar', 'raj', 'Kamal']\nname_list1 = [['AAAA'], ['BBB'], ['CCCCC']]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"89c4aa66-0fa1-4f16-8dba-5e64e79de022"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["RDD = sc.parallelize(name_list)\ndisplay(RDD)\n\nRDD1 = sc.parallelize(name_list1)\ndisplay(RDD1)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Creating RDD from list","showTitle":true,"inputWidgets":{},"nuid":"74367094-98ec-4278-a2cb-d1f5d4d614f6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"ParallelCollectionRDD[3] at readRDDFromInputStream at PythonRDD.scala:413ParallelCollectionRDD[4] at readRDDFromInputStream at PythonRDD.scala:413","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["ParallelCollectionRDD[3] at readRDDFromInputStream at PythonRDD.scala:413ParallelCollectionRDD[4] at readRDDFromInputStream at PythonRDD.scala:413"]}}],"execution_count":0},{"cell_type":"code","source":["type(RDD)\ntype(RDD1)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ffae98bf-4d3d-45c9-811f-8b0e17a9e221"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[15]: pyspark.rdd.RDD","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[15]: pyspark.rdd.RDD"]}}],"execution_count":0},{"cell_type":"code","source":["RDD.collect()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5ad8f9fb-6b38-4a83-b610-90825c0b0d85"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[17]: ['Azar', 'raj', 'Kamal']","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[17]: ['Azar', 'raj', 'Kamal']"]}}],"execution_count":0},{"cell_type":"code","source":["RDD1.collect()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a9b370bb-646e-49d7-b1c0-7f32cdb06c80"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[18]: [['AAAA'], ['BBB'], ['CCCCC']]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[18]: [['AAAA'], ['BBB'], ['CCCCC']]"]}}],"execution_count":0},{"cell_type":"code","source":["df = spark.createDataFrame(RDD, ['Name'])\ndf.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Convert RDD to DataFrame","showTitle":true,"inputWidgets":{},"nuid":"2b182281-bded-4f55-8ec0-f8b59e66c0b5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)\n\u001B[0;32m<command-2177072794751878>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mdf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mspark\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcreateDataFrame\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mRDD\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m'Name'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshow\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/sql/session.py\u001B[0m in \u001B[0;36mcreateDataFrame\u001B[0;34m(self, data, schema, samplingRatio, verifySchema)\u001B[0m\n\u001B[1;32m    720\u001B[0m             return super(SparkSession, self).createDataFrame(\n\u001B[1;32m    721\u001B[0m                 data, schema, samplingRatio, verifySchema)\n\u001B[0;32m--> 722\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_create_dataframe\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mschema\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msamplingRatio\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverifySchema\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    723\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    724\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_create_dataframe\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mschema\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msamplingRatio\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverifySchema\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/sql/session.py\u001B[0m in \u001B[0;36m_create_dataframe\u001B[0;34m(self, data, schema, samplingRatio, verifySchema)\u001B[0m\n\u001B[1;32m    750\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    751\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mRDD\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 752\u001B[0;31m                 \u001B[0mrdd\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mschema\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_createFromRDD\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprepare\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mschema\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msamplingRatio\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    753\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    754\u001B[0m                 \u001B[0mrdd\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mschema\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_createFromLocal\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprepare\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mschema\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/sql/session.py\u001B[0m in \u001B[0;36m_createFromRDD\u001B[0;34m(self, rdd, schema, samplingRatio)\u001B[0m\n\u001B[1;32m    485\u001B[0m         \"\"\"\n\u001B[1;32m    486\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mschema\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mschema\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mlist\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtuple\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 487\u001B[0;31m             \u001B[0mstruct\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_inferSchema\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrdd\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msamplingRatio\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnames\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mschema\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    488\u001B[0m             \u001B[0mconverter\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_create_converter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstruct\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    489\u001B[0m             \u001B[0mrdd\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mrdd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconverter\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/sql/session.py\u001B[0m in \u001B[0;36m_inferSchema\u001B[0;34m(self, rdd, samplingRatio, names)\u001B[0m\n\u001B[1;32m    465\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    466\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0msamplingRatio\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 467\u001B[0;31m             \u001B[0mschema\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_infer_schema\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfirst\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnames\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mnames\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    468\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0m_has_nulltype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mschema\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    469\u001B[0m                 \u001B[0;32mfor\u001B[0m \u001B[0mrow\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrdd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtake\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m100\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/sql/types.py\u001B[0m in \u001B[0;36m_infer_schema\u001B[0;34m(row, names)\u001B[0m\n\u001B[1;32m   1065\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1066\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1067\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Can not infer schema for type: %s\"\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0mtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrow\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1068\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1069\u001B[0m     \u001B[0mfields\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;31mTypeError\u001B[0m: Can not infer schema for type: <class 'str'>","errorSummary":"<span class='ansi-red-fg'>TypeError</span>: Can not infer schema for type: <class 'str'>","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)\n\u001B[0;32m<command-2177072794751878>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mdf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mspark\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcreateDataFrame\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mRDD\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m'Name'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshow\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/sql/session.py\u001B[0m in \u001B[0;36mcreateDataFrame\u001B[0;34m(self, data, schema, samplingRatio, verifySchema)\u001B[0m\n\u001B[1;32m    720\u001B[0m             return super(SparkSession, self).createDataFrame(\n\u001B[1;32m    721\u001B[0m                 data, schema, samplingRatio, verifySchema)\n\u001B[0;32m--> 722\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_create_dataframe\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mschema\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msamplingRatio\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverifySchema\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    723\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    724\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_create_dataframe\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mschema\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msamplingRatio\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverifySchema\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/sql/session.py\u001B[0m in \u001B[0;36m_create_dataframe\u001B[0;34m(self, data, schema, samplingRatio, verifySchema)\u001B[0m\n\u001B[1;32m    750\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    751\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mRDD\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 752\u001B[0;31m                 \u001B[0mrdd\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mschema\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_createFromRDD\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprepare\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mschema\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msamplingRatio\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    753\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    754\u001B[0m                 \u001B[0mrdd\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mschema\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_createFromLocal\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprepare\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mschema\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/sql/session.py\u001B[0m in \u001B[0;36m_createFromRDD\u001B[0;34m(self, rdd, schema, samplingRatio)\u001B[0m\n\u001B[1;32m    485\u001B[0m         \"\"\"\n\u001B[1;32m    486\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mschema\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mschema\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mlist\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtuple\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 487\u001B[0;31m             \u001B[0mstruct\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_inferSchema\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrdd\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msamplingRatio\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnames\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mschema\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    488\u001B[0m             \u001B[0mconverter\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_create_converter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstruct\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    489\u001B[0m             \u001B[0mrdd\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mrdd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconverter\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/sql/session.py\u001B[0m in \u001B[0;36m_inferSchema\u001B[0;34m(self, rdd, samplingRatio, names)\u001B[0m\n\u001B[1;32m    465\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    466\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0msamplingRatio\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 467\u001B[0;31m             \u001B[0mschema\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_infer_schema\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfirst\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnames\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mnames\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    468\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0m_has_nulltype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mschema\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    469\u001B[0m                 \u001B[0;32mfor\u001B[0m \u001B[0mrow\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrdd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtake\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m100\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/sql/types.py\u001B[0m in \u001B[0;36m_infer_schema\u001B[0;34m(row, names)\u001B[0m\n\u001B[1;32m   1065\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1066\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1067\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Can not infer schema for type: %s\"\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0mtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrow\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1068\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1069\u001B[0m     \u001B[0mfields\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;31mTypeError\u001B[0m: Can not infer schema for type: <class 'str'>"]}}],"execution_count":0},{"cell_type":"code","source":["df1 = spark.createDataFrame(RDD1, ['Name'])\ndf1.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9145b304-960a-41c4-8f7b-162e3cb43f74"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-----+\n| Name|\n+-----+\n| AAAA|\n|  BBB|\n|CCCCC|\n+-----+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----+\n| Name|\n+-----+\n| AAAA|\n|  BBB|\n|CCCCC|\n+-----+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["RDD2 = df1.rdd\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Converting DF to RDD","showTitle":true,"inputWidgets":{},"nuid":"0c73fe95-1620-40bb-bf63-66679e166281"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["type(RDD2)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0ab907df-a3fc-492b-a69a-248318b7335a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[22]: pyspark.rdd.RDD","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[22]: pyspark.rdd.RDD"]}}],"execution_count":0},{"cell_type":"code","source":["RDD2.collect()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9d62182d-c1b0-4199-ac06-a74ddb28cac8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[23]: [Row(Name='AAAA'), Row(Name='BBB'), Row(Name='CCCCC')]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[23]: [Row(Name='AAAA'), Row(Name='BBB'), Row(Name='CCCCC')]"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3f2e603b-8716-4178-9456-a5ce8778029d"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Create_RDD","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":2177072794751868}},"nbformat":4,"nbformat_minor":0}
